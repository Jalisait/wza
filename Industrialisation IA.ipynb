{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81e83003",
   "metadata": {},
   "source": [
    "Preprocessing complet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "271cb605",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def preprocess_all(path_train_input: str, path_test_input: str, path_train_output: str, n_train: int = 383610):\n",
    "    \"\"\"\n",
    "    Pr√©traitement simplifi√© sans normalisation, uniquement typage et nettoyage.\n",
    "    \"\"\"\n",
    "    print(\"üì• Chargement des fichiers...\")\n",
    "    test_input_train = pd.read_csv(path_train_input)\n",
    "    test_input_real = pd.read_csv(path_test_input)\n",
    "    train_output = pd.read_csv(path_train_output)\n",
    "\n",
    "    print(\"üîó Fusion des inputs...\")\n",
    "    train_input = pd.concat([test_input_train, test_input_real], ignore_index=True)\n",
    "\n",
    "    print(\"üß¨ Fusion des donn√©es sur 'ID' avec train_output...\")\n",
    "    df = train_input.merge(train_output, on=\"ID\", how=\"left\")\n",
    "\n",
    "    if 'ANNEE_ASSURANCE_x' in df.columns and 'ANNEE_ASSURANCE_y' in df.columns:\n",
    "        df.drop(columns=['ANNEE_ASSURANCE_y'], inplace=True)\n",
    "        df.rename(columns={'ANNEE_ASSURANCE_x': 'ANNEE_ASSURANCE'}, inplace=True)\n",
    "\n",
    "    if \"ZONE\" in df.columns:\n",
    "        df[\"ZONE\"] = df[\"ZONE\"].astype(str).str.strip().astype(\"category\")\n",
    "\n",
    "    print(\"üéØ S√©paration features / cibles...\")\n",
    "    y = df[[\"FREQ\", \"CM\"]].copy()\n",
    "    columns_to_drop = ['FREQ', 'CM', 'CHARGE']\n",
    "    X = df.drop(columns=columns_to_drop, errors='ignore').copy()\n",
    "\n",
    "    print(\"üîÑ Conversion des colonnes...\")\n",
    "    for col in X.columns:\n",
    "        try:\n",
    "            X[col] = pd.to_numeric(X[col], errors='raise')\n",
    "        except:\n",
    "            X[col] = X[col].astype(str).str.strip().astype('category')\n",
    "\n",
    "    print(\"‚úÇÔ∏è D√©coupage train/test...\")\n",
    "    X_train = X.iloc[:n_train].copy()\n",
    "    X_test = X.iloc[n_train:].copy()\n",
    "    y_train_freq = y[\"FREQ\"].iloc[:n_train].copy()\n",
    "    y_train_cm = y[\"CM\"].iloc[:n_train].copy()\n",
    "\n",
    "    print(\"‚úÖ Preprocessing termin√©.\")\n",
    "    print(f\" - X final : {X.shape}\")\n",
    "    print(f\" - y final : {y.shape}\")\n",
    "    print(f\" - X_train : {X_train.shape}\")\n",
    "    print(f\" - X_test  : {X_test.shape}\")\n",
    "    print(f\" - y_train_freq : {y_train_freq.shape}\")\n",
    "    print(f\" - y_train_cm   : {y_train_cm.shape}\")\n",
    "\n",
    "    return X_train, X_test, y_train_freq, y_train_cm, df, X, y\n",
    "\n",
    "X_train, X_test, y_train_freq, y_train_cm, df, X, y = preprocess_all(\n",
    "    \"train_input.csv\",\n",
    "    \"test_input.csv\",\n",
    "    \"train_output.csv\"\n",
    ")\n",
    "\n",
    "print(\"\\nüìÇ Colonnes finales utilis√©es (X.columns) :\")\n",
    "print(list(X.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4acdd567",
   "metadata": {},
   "source": [
    "Entrainement des 2 mod√®les"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e46765f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.utils._testing import ignore_warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "import warnings\n",
    "import numpy as np\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "\n",
    "@ignore_warnings(category=ConvergenceWarning)\n",
    "def train_model_freq(X_train, y_train_freq, X_test):\n",
    "    print(\"üéØ Entra√Ænement mod√®le FREQ avec Optuna\")\n",
    "\n",
    "    # √âchantillonnage\n",
    "    sample_idx = np.random.choice(X_train.index, size=50000, replace=False)\n",
    "    X_sample = X_train.loc[sample_idx]\n",
    "    y_sample = y_train_freq.loc[sample_idx]\n",
    "\n",
    "    def objective(trial):\n",
    "        params = {\n",
    "            'n_estimators': trial.suggest_int('n_estimators', 50, 150),\n",
    "            'max_depth': trial.suggest_int('max_depth', 2, 4),\n",
    "            'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.1),\n",
    "            'subsample': trial.suggest_float('subsample', 0.7, 1.0),\n",
    "            'colsample_bytree': trial.suggest_float('colsample_bytree', 0.7, 1.0),\n",
    "            'reg_lambda': trial.suggest_float('reg_lambda', 0.0, 5.0),\n",
    "            'reg_alpha': trial.suggest_float('reg_alpha', 0.0, 5.0),\n",
    "            'random_state': 42,\n",
    "            'enable_categorical': True,\n",
    "            'objective': 'reg:squarederror',\n",
    "            'n_jobs': -1\n",
    "        }\n",
    "        model = XGBRegressor(**params)\n",
    "        return cross_val_score(model, X_sample, y_sample, cv=2, scoring='r2', n_jobs=-1).mean()\n",
    "\n",
    "    study = optuna.create_study(direction=\"maximize\")\n",
    "    study.optimize(objective, n_trials=10, show_progress_bar=True)\n",
    "\n",
    "    print(f\"‚úÖ Best params FREQ : {study.best_params}\")\n",
    "    model = XGBRegressor(**study.best_params, enable_categorical=True, objective='reg:squarederror', random_state=42)\n",
    "    model.fit(X_train, y_train_freq)\n",
    "\n",
    "    # Sauvegarde\n",
    "    with open(\"model_freq.pkl\", \"wb\") as f:\n",
    "        pickle.dump(model, f)\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    return y_pred, model\n",
    "\n",
    "################################################################################################\n",
    "\n",
    "@ignore_warnings(category=ConvergenceWarning)\n",
    "def train_model_cm(X_train, y_train_cm, X_test):\n",
    "    print(\"üéØ Entra√Ænement mod√®le CM avec Optuna\")\n",
    "\n",
    "    # √âchantillonnage\n",
    "    sample_size = min(50000, len(X_train))\n",
    "    sample_idx = np.random.choice(X_train.index, size=sample_size, replace=False)\n",
    "    X_sample = X_train.loc[sample_idx]\n",
    "    y_sample = y_train_cm.loc[sample_idx]\n",
    "\n",
    "    def objective(trial):\n",
    "        params = {\n",
    "            'n_estimators': trial.suggest_int('n_estimators', 50, 150),\n",
    "            'max_depth': trial.suggest_int('max_depth', 2, 5),\n",
    "            'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.1),\n",
    "            'subsample': trial.suggest_float('subsample', 0.7, 1.0),\n",
    "            'colsample_bytree': trial.suggest_float('colsample_bytree', 0.7, 1.0),\n",
    "            'reg_lambda': trial.suggest_float('reg_lambda', 0.0, 5.0),\n",
    "            'reg_alpha': trial.suggest_float('reg_alpha', 0.0, 5.0),\n",
    "            'enable_categorical': True,\n",
    "            'objective': 'reg:squarederror',\n",
    "            'random_state': 42,\n",
    "            'n_jobs': -1\n",
    "        }\n",
    "        model = XGBRegressor(**params)\n",
    "        return cross_val_score(model, X_sample, y_sample, cv=2, scoring='r2', n_jobs=-1).mean()\n",
    "\n",
    "    study = optuna.create_study(direction=\"maximize\")\n",
    "    study.optimize(objective, n_trials=10, show_progress_bar=True)\n",
    "\n",
    "    print(f\"‚úÖ Best params CM : {study.best_params}\")\n",
    "    model = XGBRegressor(**study.best_params, enable_categorical=True, objective='reg:squarederror', random_state=42)\n",
    "    model.fit(X_train, y_train_cm)\n",
    "\n",
    "    # Sauvegarde\n",
    "    with open(\"model_cm.pkl\", \"wb\") as f:\n",
    "        pickle.dump(model, f)\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    return y_pred, model\n",
    "\n",
    "y_pred_freq, model_freq = train_model_freq(X_train, y_train_freq, X_test)\n",
    "y_pred_cm, model_cm = train_model_cm(X_train, y_train_cm, X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6202fcd7",
   "metadata": {},
   "source": [
    "R√©sultat adapt√© √† un fichier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1115b31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "def preprocess_for_prediction(input_path: str):\n",
    "    \"\"\"\n",
    "    Pr√©traitement l√©ger pour pr√©diction (sans normalisation, avec typage).\n",
    "    \"\"\"\n",
    "    print(\"üì• Chargement du fichier √† pr√©dire...\")\n",
    "    X_new = pd.read_csv(input_path)\n",
    "\n",
    "    if 'ANNEE_ASSURANCE_x' in X_new.columns and 'ANNEE_ASSURANCE_y' in X_new.columns:\n",
    "        X_new.drop(columns=['ANNEE_ASSURANCE_y'], inplace=True)\n",
    "        X_new.rename(columns={'ANNEE_ASSURANCE_x': 'ANNEE_ASSURANCE'}, inplace=True)\n",
    "\n",
    "    print(\"üîÑ Typage des colonnes...\")\n",
    "    for col in X_new.columns:\n",
    "        try:\n",
    "            X_new[col] = pd.to_numeric(X_new[col], errors='raise')\n",
    "        except:\n",
    "            X_new[col] = X_new[col].astype(str).str.strip().astype('category')\n",
    "    \n",
    "    if \"ZONE\" in X_new.columns:\n",
    "        X_new[\"ZONE\"] = X_new[\"ZONE\"].astype(str).str.strip().astype(\"category\")\n",
    "\n",
    "    print(f\"‚úÖ Donn√©es pr√™tes : {X_new.shape}\")\n",
    "    return X_new\n",
    "\n",
    "def generate_submission(input_path: str, output_path: str = \"submission.csv\"):\n",
    "    \"\"\"\n",
    "    Fonction compl√®te : chargement des mod√®les, pr√©diction sur donn√©es,\n",
    "    calcul de CHARGE, et sauvegarde en CSV.\n",
    "    \"\"\"\n",
    "    print(\"üì¶ Chargement des mod√®les...\")\n",
    "    with open(\"model_freq.pkl\", \"rb\") as f:\n",
    "        model_freq = pickle.load(f)\n",
    "    with open(\"model_cm.pkl\", \"rb\") as f:\n",
    "        model_cm = pickle.load(f)\n",
    "\n",
    "    print(\"üîç Pr√©traitement des donn√©es...\")\n",
    "    X_to_predict = preprocess_for_prediction(input_path)\n",
    "\n",
    "    print(\"üìà Pr√©dictions en cours...\")\n",
    "    y_pred_freq = model_freq.predict(X_to_predict)\n",
    "    y_pred_cm = model_cm.predict(X_to_predict)\n",
    "\n",
    "    print(\"üßÆ Construction du DataFrame de sortie...\")\n",
    "    df_submission = pd.DataFrame({\n",
    "        \"ID\": X_to_predict[\"ID\"],\n",
    "        \"FREQ\": y_pred_freq,\n",
    "        \"CM\": y_pred_cm,\n",
    "        \"ANNEE_ASSURANCE\": X_to_predict[\"ANNEE_ASSURANCE\"]\n",
    "    })\n",
    "    df_submission[\"CHARGE\"] = df_submission[\"FREQ\"] * df_submission[\"CM\"] * df_submission[\"ANNEE_ASSURANCE\"]\n",
    "\n",
    "    print(f\"üíæ Sauvegarde dans '{output_path}'...\")\n",
    "    df_submission.to_csv(output_path, index=False)\n",
    "    print(\"‚úÖ Fichier g√©n√©r√© avec succ√®s.\")\n",
    "\n",
    "generate_submission(\"test_input.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019d6bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Charge le fichier complet\n",
    "df = pd.read_csv(\"test_input.csv\")\n",
    "\n",
    "# Prend seulement les 1000 premi√®res lignes\n",
    "df_small = df.head(1000)\n",
    "\n",
    "# Sauvegarde dans un nouveau fichier\n",
    "df_small.to_csv(\"test_input_for_API.csv\", index=False)\n",
    "\n",
    "print(\"‚úÖ Nouveau fichier 'test_input_for_API.csv' cr√©√© avec 1000 lignes.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
